---
title: "How to determine the cluster number?"
author: "Shun Bi"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{How to determine the cluster number?}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(collapse = TRUE, comment = "#>",
                      fig.align='center')
```

# Lists of vignettes showing how to use FCMm

Dear users, the four vignettes of `FCMm` were provided in this package to demonstrate the usage and application to obtain the cluster number, to train the user-defined data set, to apply the default FCMm to new data (such as Chla concentration estimation), and to the imagery data.

Here are the step-by-step demos:

 - **Demo_1: How to determine the cluster number?**
 - Demo_2: How to train the fuzzy cluster?
 - Demo_3: How to apply the default FCMm to new data?
 - Demo_4: The application of FCMm to imagery data.

# Preparing the data set

This Vignette shows how to use `FCMm` package to determine the optimized cluster number about your data set. Here we use our demo data `Nechad2015`.

**Note**: we also need package `tidyverse` to string and data processing.

## Dataframe process

```{r message=FALSE, warning=FALSE}
rm(list=ls())
library(FCMm)
library(tidyverse)
data("Nechad2015")
w <- Nechad2015 %>% names %>%
  str_extract(.,pattern="\\d") %>%
  is.na %>% {!.}
wv <- w %>% names(Nechad2015)[.] %>%
  gsub('X','',.) %>% as.numeric
x <- w %>% Nechad2015[,.]
names(x) <- wv
rm(w)
```

## Spectra plot

After that, we subset Rrs dataframe (named `x`) and wavelength vector (named `wv`). It is time to plot the spectra of this set by using function `plot_spec_from_df`.

**Note**: The input of `plot_spec_from_df` should be a matrix or data.frame with colnames that could be transformed to the numeric --- as the x-axis of the plot. Since the return of `plot_spec_from_df` is a `ggplot` list, you could modify or add it for your own purpose (such as add labs or themes).

```{r fig.height=5, fig.width=6}
p.spec <- plot_spec_from_df(x) + 
  labs(x='Wavelength (nm)',y=expression(Rrs~(sr^-1))) + 
  theme_bw() + 
  theme(legend.position='none', text=element_text(size=18))
print(p.spec)
```

## FCM preparation

Before optimizing best cluster number, we have to obtain a FD list produced by function `FuzzifierDetermination` just as follows.

```{r}
FD <- FuzzifierDetermination(x, wv, stand=F)
summary(FD)
```

`FD` list contains several result by `FuzzifierDetermination`:

 - *x*: the raw input Rrs dataframe with unit sr^-1
 - *x.stand*: the standardized Rrs dataframe, if `stand=F`
 - *wv*: wavelength with unit nm
 - *max.m*: the maximum fuzzifier of FCM as a restriction
 - *stand*: logic value for choosing whether to use standardization
 - *dmetric*: string value for choosing which distance metric to be used
 - *Area*: numeric vector for trapezoidal integral values
 - *m.ub*: the upper boundary of fuzzifier(m) value
 - *m.used*: the desired value of fuzzifier(m) value

# Optimizing the best cluster number

# validate functions or metrics

Here I gonna introduce several famous cluster validate metrics such as `SIL.F`, `PE`, `PC`, and `MPC`.

In brief, these metrics mean the goodness of cluster results. Except for `PE`, the larger of `SIL.F`,  `PC`, and `MPC`, the better of cluster in that time. If you are more interested about that, please see more details in the document of package `ppclust` by Zeynel Cebeci and `fclust` by Paolo Giordani. Actually, package `FCMm` has been inspired by them a lot, and I'm very grateful.

```{r fig.height=3, fig.width=6, message=FALSE, warning=FALSE}
set.seed(1234)
FD <- x %>% 
  # sample_n(., size=300) %>%
  FuzzifierDetermination(., wv, stand=F)
nb_min <- 3
nb_max <- 10
idxsf <- idxpe <- idxpc <- idxmpc <- seq(nb_min,nb_max,1)
i <- 1
for(nb in nb_min:nb_max){
  res <- FCM.new(FD, nb, fast.mode=T) # open the fast mode
  # print(res$p.jitter)
  tmp <- ppclust::ppclust2(res$res.FCM,otype="fclust")
  idxsf[i] <- fclust::SIL.F(tmp$Xca, tmp$U, alpha=1) # optimal with maximum value
  idxpe[i] <- fclust::PE(tmp$U) # optimal with minimum value
  idxpc[i] <- fclust::PC(tmp$U) # optimal with maximum value
  idxmpc[i] <- fclust::MPC(tmp$U) # optimal with maximum value
  i <- i + 1
}

dt <- data.frame(nb=seq(nb_min,nb_max,1),idxsf,idxpe,idxpc,idxmpc)
opt.num <- c(apply(dt,2,which.max)[-c(1,3)]+1,apply(dt,2,which.min)[3]+1)

dt %>% reshape2::melt(., id='nb') %>% 
  ggplot(data=.,aes(x=nb,y=value,group=variable,color=variable)) + 
  geom_path() + 
  facet_wrap(~variable, scales='free_y', nrow=2) + 
  theme(text=element_text(size=18), legend.position='none')
```

Back to the code, here we assume the best cluster number is ranging from `r nb_min` to `r nb_max` (maybe out of this range but is so weird to obtain such large number). Then we calculate every validate metrics and record them into their corresponding vectors. Finally, we will obtain the goodness curve of cluster results changing with cluster numebr.

**Note**: the process is actually a bootstrapping way to obtain the objective result. So it will take much a long time. Well! We select `4` as the best cluster number.
